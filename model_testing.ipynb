{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the data\n",
    "data = pd.read_csv(\"rainfall.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"SUBDIVISION\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "means = data[numeric_cols].mean()\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling na values with mean\n",
    "data[numeric_cols] = data[numeric_cols].fillna(means)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.YEAR.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"SUBDIVISION\", \"ANNUAL\"]].groupby(\"SUBDIVISION\").sum().sort_values(\n",
    "    by=\"ANNUAL\", ascending=False\n",
    ").plot(kind=\"barh\", stacked=True, figsize=(15, 10))\n",
    "\n",
    "plt.xlabel(\"Rainfall in MM\", size=12)\n",
    "plt.ylabel(\"Sub-Division\", size=12)\n",
    "plt.title(\"Annual Rainfall v/s SubDivisions\")\n",
    "plt.grid(axis=\"x\", linestyle=\"-.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "data.groupby(\"YEAR\").sum()['ANNUAL'].plot(kind=\"line\",color=\"r\",marker=\".\")\n",
    "\n",
    "plt.xlabel(\"YEARS\",size=12)\n",
    "plt.ylabel(\"RAINFALL IN MM\",size=12)\n",
    "plt.grid(axis=\"both\",linestyle=\"-.\")\n",
    "plt.title(\"Rainfall over Years\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['YEAR', 'JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL','AUG', 'SEP',\n",
    "      'OCT', 'NOV', 'DEC']].groupby(\"YEAR\").sum().plot(kind=\"line\",figsize=(18,8))\n",
    "\n",
    "plt.xlabel(\"Year\",size=13)\n",
    "plt.ylabel(\"Rainfall in MM\",size=13)\n",
    "plt.title(\"Year v/s Rainfall in each month\",size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"YEAR\", \"Jan-Feb\", \"Mar-May\", \"Jun-Sep\", \"Oct-Dec\"]].groupby(\"YEAR\").sum().plot(\n",
    "    figsize=(10, 7)\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Year\", size=13)\n",
    "plt.ylabel(\"Rainfall in MM\", size=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['SUBDIVISION', 'JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL',\n",
    "       'AUG', 'SEP', 'OCT', 'NOV', 'DEC']].groupby(\"SUBDIVISION\").sum().plot(kind=\"barh\",stacked=True,figsize=(13,8))\n",
    "\n",
    "plt.title(\"Sub-Division v/s Rainfall in each month\")\n",
    "plt.xlabel(\"Rainfall in MM\",size=12)\n",
    "plt.ylabel(\"Sub-Division\",size=12)\n",
    "plt.grid(axis=\"x\",linestyle=\"-.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"SUBDIVISION\", \"Jan-Feb\", \"Mar-May\", \"Jun-Sep\", \"Oct-Dec\"]].groupby(\n",
    "    \"SUBDIVISION\"\n",
    ").sum().plot(kind=\"barh\", stacked=True, figsize=(16, 8))\n",
    "\n",
    "plt.xlabel(\"Rainfall in MM\", size=12)\n",
    "plt.ylabel(\"Sub-Division\", size=12)\n",
    "plt.grid(axis=\"x\", linestyle=\"-.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis of rainfall data of west bengal\n",
    "WestBengal = data.loc[((data['SUBDIVISION'] == 'GANGETIC WEST BENGAL'))]\n",
    "WestBengal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "WestBengal[['JAN', 'FEB', 'MAR', 'APR','MAY', 'JUN','JUL','AUG', 'SEP', 'OCT','NOV','DEC']].mean().plot(kind=\"bar\",width=0.5,linewidth=2)\n",
    "plt.title(\"West Bengal Rainfall v/s Months\",size=20)\n",
    "plt.xlabel(\"Months\",size=14)\n",
    "plt.ylabel(\"Rainfall in MM\",size=14)\n",
    "plt.grid(axis=\"both\",linestyle=\"-.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_mean = WestBengal.groupby(\"YEAR\")['ANNUAL'].mean()\n",
    "\n",
    "# Plot the data\n",
    "annual_mean.plot(ylim=(50,1500), color='r', marker='o', linestyle='-', linewidth=2, figsize=(12,8))\n",
    "plt.xlabel('Year', size=14)\n",
    "plt.ylabel('Rainfall in MM', size=14)\n",
    "plt.title('West Bengal Annual Rainfall from Year 1901 to 2015', size=20)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "sns.heatmap(data[['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC','ANNUAL']].corr(),annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"SUBDIVISION\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = data.groupby(\"SUBDIVISION\")[\n",
    "    [\"YEAR\", \"JAN\", \"FEB\", \"MAR\", \"APR\", \"MAY\", \"JUN\", \"JUL\", \"AUG\", \"SEP\", \"OCT\", \"NOV\", \"DEC\"]\n",
    "]\n",
    "data=group.get_group(('GANGETIC WEST BENGAL'))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.melt([\"YEAR\"]).reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"YEAR\", \"variable\", \"value\"]].reset_index().sort_values(by=[\"YEAR\", \"index\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.YEAR.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"Index\", \"Year\", \"Month\", \"Avg_Rainfall\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Month_map = {\n",
    "    \"JAN\": 1,\n",
    "    \"FEB\": 2,\n",
    "    \"MAR\": 3,\n",
    "    \"APR\": 4,\n",
    "    \"MAY\": 5,\n",
    "    \"JUN\": 6,\n",
    "    \"JUL\": 7,\n",
    "    \"AUG\": 8,\n",
    "    \"SEP\": 9,\n",
    "    \"OCT\": 10,\n",
    "    \"NOV\": 11,\n",
    "    \"DEC\": 12,\n",
    "}\n",
    "df[\"Month\"] = df[\"Month\"].map(Month_map)\n",
    "df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=\"Index\", inplace=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Year\").sum().plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asanyarray(df[[\"Year\", \"Month\"]]).astype(\"int\")\n",
    "y = np.asanyarray(df[\"Avg_Rainfall\"]).astype(\"int\")\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataset into training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Liner Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "LR = LinearRegression()\n",
    "LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting \n",
    "y_train_predict=LR.predict(X_train)\n",
    "y_test_predict=LR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-------Test Data--------\")\n",
    "print(\"MAE:\", metrics.mean_absolute_error(y_test, y_test_predict))\n",
    "print(\"MSE:\", metrics.mean_squared_error(y_test, y_test_predict))\n",
    "print(\"RMSE:\", np.sqrt(metrics.mean_squared_error(y_test, y_test_predict)))\n",
    "\n",
    "print(\"\\n-------Train Data--------\")\n",
    "print(\"MAE:\", metrics.mean_absolute_error(y_train, y_train_predict))\n",
    "print(\"MSE:\", metrics.mean_squared_error(y_train, y_train_predict))\n",
    "print(\"RMSE:\", np.sqrt(metrics.mean_squared_error(y_train, y_train_predict)))\n",
    "\n",
    "print(\"\\n-----Training Accuracy-------\")\n",
    "print(round(LR.score(X_train, y_train), 3) * 100)\n",
    "print(\"-----Testing Accuracy--------\")\n",
    "print(round(LR.score(X_test, y_test), 3) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# create a lasso object\n",
    "lasso = Lasso(max_iter=100000)\n",
    "\n",
    "# check for best alpha value using GridSearch\n",
    "parameter = {\n",
    "    \"alpha\": [1e-15, 1e-10, 1e-8, 1e-3, 1e-2, 1, 5, 1e1, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7]\n",
    "}\n",
    "lasso_regressor = GridSearchCV(lasso, parameter, scoring=\"neg_mean_squared_error\", cv=5)\n",
    "\n",
    "lasso_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Parameter for Lasso:\", lasso_regressor.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=100.0, max_iter=100000)\n",
    "# fit into the object\n",
    "lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting \n",
    "y_train_predict=lasso.predict(X_train)\n",
    "y_test_predict=lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(\"-------Test Data--------\")\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_test_predict))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, y_test_predict))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_test_predict)))\n",
    "\n",
    "print(\"\\n-------Train Data--------\")\n",
    "print('MAE:', metrics.mean_absolute_error(y_train,y_train_predict))\n",
    "print('MSE:', metrics.mean_squared_error(y_train, y_train_predict))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_train, y_train_predict)))\n",
    "\n",
    "print(\"\\n-----Training Accuracy-------\")\n",
    "print(round(lasso.score(X_train,y_train),3)*100)\n",
    "print(\"-----Testing Accuracy--------\")\n",
    "print(round(lasso.score(X_test,y_test),3)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "ridge = Ridge()\n",
    "parameters = {\n",
    "    \"alpha\": [1e-15, 1e-10, 1e-8, 1e-3, 1e-2, 1, 5, 10, 20, 30, 35, 40, 45, 50, 55, 100]\n",
    "}\n",
    "ridge_regressor = GridSearchCV(\n",
    "    ridge, parameters, scoring=\"neg_mean_squared_error\", cv=5\n",
    ")\n",
    "ridge_regressor.fit(X_train, y_train)\n",
    "\n",
    "print(ridge_regressor.best_params_)\n",
    "print(ridge_regressor.best_score_)\n",
    "print(\"Best Parameter for Ridge:\", ridge_regressor.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge=Ridge(alpha=100.0)\n",
    "\n",
    "# fit into the object\n",
    "ridge.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting the train and test values\n",
    "y_train_predict = ridge.predict(X_train)\n",
    "y_test_predict = ridge.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"-------Test Data--------\")\n",
    "print(\"MAE:\", metrics.mean_absolute_error(y_test, y_test_predict))\n",
    "print(\"MSE:\", metrics.mean_squared_error(y_test, y_test_predict))\n",
    "print(\"RMSE:\", np.sqrt(metrics.mean_squared_error(y_test, y_test_predict)))\n",
    "\n",
    "print(\"\\n-------Train Data--------\")\n",
    "print(\"MAE:\", metrics.mean_absolute_error(y_train, y_train_predict))\n",
    "print(\"MSE:\", metrics.mean_squared_error(y_train, y_train_predict))\n",
    "print(\"RMSE:\", np.sqrt(metrics.mean_squared_error(y_train, y_train_predict)))\n",
    "\n",
    "print(\"\\n-----Training Accuracy-------\")\n",
    "print(round(ridge.score(X_train, y_train), 3) * 100)\n",
    "print(\"-----Testing Accuracy--------\")\n",
    "print(round(ridge.score(X_test, y_test), 3) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, svm\n",
    "\n",
    "svm_regr = svm.SVC(kernel=\"rbf\")\n",
    "svm_regr.fit(X_train, y_train)\n",
    "\n",
    "y_test_predict = svm_regr.predict(X_test)\n",
    "y_train_predict = svm_regr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(\"-------Test Data--------\")\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_test_predict))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, y_test_predict))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_test_predict)))\n",
    "\n",
    "print(\"\\n-------Train Data--------\")\n",
    "print('MAE:', metrics.mean_absolute_error(y_train,y_train_predict))\n",
    "print('MSE:', metrics.mean_squared_error(y_train, y_train_predict))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_train, y_train_predict)))\n",
    "\n",
    "\n",
    "print(\"\\n-----Training Accuracy-------\")\n",
    "print(round(svm_regr.score(X_train,y_train),3)*100)\n",
    "print(\"-----Testing Accuracy--------\")\n",
    "print(round(svm_regr.score(X_test,y_test),3)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "random_forest_model = RandomForestRegressor(\n",
    "    max_depth=100,\n",
    "    max_features=\"sqrt\",\n",
    "    min_samples_leaf=4,\n",
    "    min_samples_split=10,\n",
    "    n_estimators=800,\n",
    ")\n",
    "random_forest_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = random_forest_model.predict(X_train)\n",
    "y_test_predict = random_forest_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-------Test Data--------\")\n",
    "print(\"MAE:\", metrics.mean_absolute_error(y_test, y_test_predict))\n",
    "print(\"MSE:\", metrics.mean_squared_error(y_test, y_test_predict))\n",
    "print(\"RMSE:\", np.sqrt(metrics.mean_squared_error(y_test, y_test_predict)))\n",
    "\n",
    "print(\"\\n-------Train Data--------\")\n",
    "print(\"MAE:\", metrics.mean_absolute_error(y_train, y_train_predict))\n",
    "print(\"MSE:\", metrics.mean_squared_error(y_train, y_train_predict))\n",
    "print(\"RMSE:\", np.sqrt(metrics.mean_squared_error(y_train, y_train_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----------Training Accuracy------------\")\n",
    "print(round(random_forest_model.score(X_train, y_train), 3) * 100)\n",
    "print(\"-----------Testing Accuracy------------\")\n",
    "print(round(random_forest_model.score(X_test, y_test), 3) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = random_forest_model.predict([[2016, 11]])\n",
    "predicted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
